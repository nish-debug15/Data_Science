{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addeecc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "    ORDERNUMBER  QUANTITYORDERED  PRICEEACH  ORDERLINENUMBER    SALES  \\\n",
      "0        10107               30      95.70                2  2871.00   \n",
      "1        10121               34      81.35                5  2765.90   \n",
      "2        10134               41      94.74                2  3884.34   \n",
      "3        10145               45      83.26                6  3746.70   \n",
      "4        10159               49     100.00               14  5205.27   \n",
      "\n",
      "         ORDERDATE   STATUS  QTR_ID  MONTH_ID  YEAR_ID  ...  \\\n",
      "0   2/24/2003 0:00  Shipped       1         2     2003  ...   \n",
      "1    5/7/2003 0:00  Shipped       2         5     2003  ...   \n",
      "2    7/1/2003 0:00  Shipped       3         7     2003  ...   \n",
      "3   8/25/2003 0:00  Shipped       3         8     2003  ...   \n",
      "4  10/10/2003 0:00  Shipped       4        10     2003  ...   \n",
      "\n",
      "                    ADDRESSLINE1  ADDRESSLINE2           CITY STATE  \\\n",
      "0        897 Long Airport Avenue           NaN            NYC    NY   \n",
      "1             59 rue de l'Abbaye           NaN          Reims   NaN   \n",
      "2  27 rue du Colonel Pierre Avia           NaN          Paris   NaN   \n",
      "3             78934 Hillside Dr.           NaN       Pasadena    CA   \n",
      "4                7734 Strong St.           NaN  San Francisco    CA   \n",
      "\n",
      "  POSTALCODE COUNTRY TERRITORY CONTACTLASTNAME CONTACTFIRSTNAME DEALSIZE  \n",
      "0      10022     USA       NaN              Yu             Kwai    Small  \n",
      "1      51100  France      EMEA         Henriot             Paul    Small  \n",
      "2      75508  France      EMEA        Da Cunha           Daniel   Medium  \n",
      "3      90003     USA       NaN           Young            Julie   Medium  \n",
      "4        NaN     USA       NaN           Brown            Julie   Medium  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Transformed Data:\n",
      "    ORDERNUMBER  QUANTITYORDERED  PRICEEACH  ORDERLINENUMBER  order_amount  \\\n",
      "0        10107               30      95.70                2       2871.00   \n",
      "1        10121               34      81.35                5       2765.90   \n",
      "2        10134               41      94.74                2       3884.34   \n",
      "3        10145               45      83.26                6       3746.70   \n",
      "4        10159               49     100.00               14       5205.27   \n",
      "\n",
      "  order_date   STATUS  QTR_ID  MONTH_ID  YEAR_ID  ...           CITY  STATE  \\\n",
      "0        NaT  Shipped       1         2     2003  ...            NYC     NY   \n",
      "1        NaT  Shipped       2         5     2003  ...          Reims    NaN   \n",
      "2        NaT  Shipped       3         7     2003  ...          Paris    NaN   \n",
      "3        NaT  Shipped       3         8     2003  ...       Pasadena     CA   \n",
      "4        NaT  Shipped       4        10     2003  ...  San Francisco     CA   \n",
      "\n",
      "  POSTALCODE COUNTRY region CONTACTLASTNAME CONTACTFIRSTNAME DEALSIZE  \\\n",
      "0      10022     USA    Nan              Yu             Kwai    Small   \n",
      "1      51100  France   Emea         Henriot             Paul    Small   \n",
      "2      75508  France   Emea        Da Cunha           Daniel   Medium   \n",
      "3      90003     USA    Nan           Young            Julie   Medium   \n",
      "4        NaN     USA    Nan           Brown            Julie   Medium   \n",
      "\n",
      "  region_encoded order_amount_normalized  \n",
      "0              0                0.175644  \n",
      "1              1                0.167916  \n",
      "2              1                0.250150  \n",
      "3              0                0.240030  \n",
      "4              0                0.347273  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "\n",
      "Missing Values:\n",
      " ORDERNUMBER                   0\n",
      "QUANTITYORDERED               0\n",
      "PRICEEACH                     0\n",
      "ORDERLINENUMBER               0\n",
      "order_amount                  0\n",
      "order_date                 2823\n",
      "STATUS                        0\n",
      "QTR_ID                        0\n",
      "MONTH_ID                      0\n",
      "YEAR_ID                       0\n",
      "PRODUCTLINE                   0\n",
      "MSRP                          0\n",
      "PRODUCTCODE                   0\n",
      "CUSTOMERNAME                  0\n",
      "PHONE                         0\n",
      "ADDRESSLINE1                  0\n",
      "ADDRESSLINE2               2521\n",
      "CITY                          0\n",
      "STATE                      1486\n",
      "POSTALCODE                   76\n",
      "COUNTRY                       0\n",
      "region                        0\n",
      "CONTACTLASTNAME               0\n",
      "CONTACTFIRSTNAME              0\n",
      "DEALSIZE                      0\n",
      "region_encoded                0\n",
      "order_amount_normalized       0\n",
      "dtype: int64\n",
      "\n",
      "Region Mapping: {'Nan': 0, 'Emea': 1, 'Apac': 2, 'Japan': 3, 'Unknown': 0}\n",
      "\n",
      "Transformed data saved to 'transformed_sales_data.csv'\n"
     ]
    }
   ],
   "source": [
    "#p2\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Step 1: Load dataset\n",
    "file_path = \"N:\\CS2225 DS\\Datasets\\p2.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(file_path, encoding='latin1')  \n",
    "    print(\"Original Data:\\n\", df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{file_path}' not found. Please check the file path.\")\n",
    "    exit(1)\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(f\"Error: The file '{file_path}' is empty or invalid.\")\n",
    "    exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Error reading CSV file: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "\n",
    "# Step 2: Check if required columns exist\n",
    "required_columns = ['ORDERDATE', 'TERRITORY', 'SALES']\n",
    "if not all(col in df.columns for col in required_columns):\n",
    "    print(f\"Error: Required columns {required_columns} not found. Available columns: {list(df.columns)}\")\n",
    "    exit(1)\n",
    "\n",
    "\n",
    "# Step 3: Rename columns to match expected names\n",
    "df = df.rename(columns={'ORDERDATE': 'order_date', 'TERRITORY': 'region', 'SALES': 'order_amount'})\n",
    "\n",
    "\n",
    "# Step 4: Data Wrangling\n",
    "# Handle missing values\n",
    "df['order_date'] = df['order_date'].fillna('2023-01-01')  # Fill missing dates\n",
    "df['region'] = df['region'].astype(str).fillna('Unknown')  # Fill missing regions\n",
    "try:\n",
    "    df['order_amount'] = pd.to_numeric(df['order_amount'], errors='coerce')\n",
    "    df['order_amount'] = df['order_amount'].fillna(df['order_amount'].mean())\n",
    "except Exception as e:\n",
    "    print(f\"Error handling 'order_amount' column: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Standardize date format\n",
    "try:\n",
    "    df['order_date'] = pd.to_datetime(df['order_date'], errors='coerce', format='%Y-%m-%d')\n",
    "except Exception as e:\n",
    "    print(f\"Error converting 'order_date' to datetime: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Standardize categorical variables (region to title case)\n",
    "df['region'] = df['region'].str.title()\n",
    "\n",
    "# Encode categorical variable (region) to numerical\n",
    "unique_regions = df['region'].unique()\n",
    "region_mapping = {region: idx for idx, region in enumerate(unique_regions, start=0)}\n",
    "region_mapping['Unknown'] = 0  # Ensure Unknown maps to 0\n",
    "df['region_encoded'] = df['region'].map(region_mapping)\n",
    "# Normalize numerical data (order_amount)\n",
    "try:\n",
    "    scaler = MinMaxScaler()\n",
    "    df['order_amount_normalized'] = scaler.fit_transform(df[['order_amount']].fillna(df['order_amount'].mean()))\n",
    "except Exception as e:\n",
    "    print(f\"Error normalizing 'order_amount': {e}\")\n",
    "    exit(1)\n",
    "\n",
    "\n",
    "# Step 5: Display transformed data\n",
    "print(\"\\nTransformed Data:\\n\", df.head())\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
    "print(\"\\nRegion Mapping:\", region_mapping)\n",
    "\n",
    "\n",
    "# Step 6: Save transformed data\n",
    "try:\n",
    "    df.to_csv(\"transformed_sales_data.csv\", index=False)\n",
    "    print(\"\\nTransformed data saved to 'transformed_sales_data.csv'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving transformed data: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e9494d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed with encoding utf-8: 'utf-8' codec can't decode byte 0x84 in position 8: invalid start byte\n",
      "File read successfully with encoding: latin1\n",
      "Original Data:\n",
      "    ORDERNUMBER  QUANTITYORDERED  PRICEEACH  ORDERLINENUMBER    SALES  \\\n",
      "0        10107               30      95.70                2  2871.00   \n",
      "1        10121               34      81.35                5  2765.90   \n",
      "2        10134               41      94.74                2  3884.34   \n",
      "3        10145               45      83.26                6  3746.70   \n",
      "4        10159               49     100.00               14  5205.27   \n",
      "\n",
      "         ORDERDATE   STATUS  QTR_ID  MONTH_ID  YEAR_ID  ...  \\\n",
      "0   2/24/2003 0:00  Shipped       1         2     2003  ...   \n",
      "1    5/7/2003 0:00  Shipped       2         5     2003  ...   \n",
      "2    7/1/2003 0:00  Shipped       3         7     2003  ...   \n",
      "3   8/25/2003 0:00  Shipped       3         8     2003  ...   \n",
      "4  10/10/2003 0:00  Shipped       4        10     2003  ...   \n",
      "\n",
      "                    ADDRESSLINE1  ADDRESSLINE2           CITY STATE  \\\n",
      "0        897 Long Airport Avenue           NaN            NYC    NY   \n",
      "1             59 rue de l'Abbaye           NaN          Reims   NaN   \n",
      "2  27 rue du Colonel Pierre Avia           NaN          Paris   NaN   \n",
      "3             78934 Hillside Dr.           NaN       Pasadena    CA   \n",
      "4                7734 Strong St.           NaN  San Francisco    CA   \n",
      "\n",
      "  POSTALCODE COUNTRY TERRITORY CONTACTLASTNAME CONTACTFIRSTNAME DEALSIZE  \n",
      "0      10022     USA       NaN              Yu             Kwai    Small  \n",
      "1      51100  France      EMEA         Henriot             Paul    Small  \n",
      "2      75508  France      EMEA        Da Cunha           Daniel   Medium  \n",
      "3      90003     USA       NaN           Young            Julie   Medium  \n",
      "4        NaN     USA       NaN           Brown            Julie   Medium  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Transformed data saved to 'cleaned_shipments.csv'\n",
      "\n",
      "Transformed Data (first 5 rows):\n",
      "    ORDERNUMBER  QUANTITYORDERED  PRICEEACH  ORDERLINENUMBER    SALES  \\\n",
      "0        10107               30      95.70                2  2871.00   \n",
      "1        10121               34      81.35                5  2765.90   \n",
      "2        10134               41      94.74                2  3884.34   \n",
      "3        10145               45      83.26                6  3746.70   \n",
      "4        10159               49     100.00               14  5205.27   \n",
      "\n",
      "         ORDERDATE   STATUS  QTR_ID  MONTH_ID  YEAR_ID  ...  \\\n",
      "0   2/24/2003 0:00  Shipped       1         2     2003  ...   \n",
      "1    5/7/2003 0:00  Shipped       2         5     2003  ...   \n",
      "2    7/1/2003 0:00  Shipped       3         7     2003  ...   \n",
      "3   8/25/2003 0:00  Shipped       3         8     2003  ...   \n",
      "4  10/10/2003 0:00  Shipped       4        10     2003  ...   \n",
      "\n",
      "                    ADDRESSLINE1  ADDRESSLINE2           CITY STATE  \\\n",
      "0        897 Long Airport Avenue           NaN            NYC    NY   \n",
      "1             59 rue de l'Abbaye           NaN          Reims   NaN   \n",
      "2  27 rue du Colonel Pierre Avia           NaN          Paris   NaN   \n",
      "3             78934 Hillside Dr.           NaN       Pasadena    CA   \n",
      "4                7734 Strong St.           NaN  San Francisco    CA   \n",
      "\n",
      "  POSTALCODE COUNTRY TERRITORY CONTACTLASTNAME CONTACTFIRSTNAME DEALSIZE  \n",
      "0      10022     USA       NaN              Yu             Kwai    Small  \n",
      "1      51100  France      EMEA         Henriot             Paul    Small  \n",
      "2      75508  France      EMEA        Da Cunha           Daniel   Medium  \n",
      "3      90003     USA       NaN           Young            Julie   Medium  \n",
      "4        NaN     USA       NaN           Brown            Julie   Medium  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "#ex2\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "\n",
    "file_path = \"N:\\CS2225 DS\\Datasets\\p2.csv\"   \n",
    "\n",
    "df = None\n",
    "for enc in [\"utf-8\", \"latin1\", \"cp1252\"]:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding=enc)\n",
    "        print(f\"File read successfully with encoding: {enc}\")\n",
    "        print(\"Original Data:\\n\", df.head())\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Failed with encoding {enc}: {e}\")\n",
    "\n",
    "if df is not None:\n",
    "    if 'delivery_date' in df.columns:\n",
    "        df['delivery_date'] = pd.to_datetime(df['delivery_date'], errors='coerce', dayfirst=False)\n",
    "        df['delivery_date'] = df['delivery_date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    if 'destination' in df.columns:\n",
    "        df['destination'] = df['destination'].astype(str).str.title()\n",
    "\n",
    "    if 'destination' in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        df['destination_encoded'] = le.fit_transform(df['destination'])\n",
    "\n",
    "        destination_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "        print(\"\\nDestination Mapping:\", destination_mapping)\n",
    "    \n",
    "\n",
    "    output_file = \"cleaned_shipments.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nTransformed data saved to '{output_file}'\")\n",
    "\n",
    "\n",
    "    print(\"\\nTransformed Data (first 5 rows):\\n\", df.head())\n",
    "\n",
    "else:\n",
    "    print(\"Could not read file with any tested encoding.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
